{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown,display, update_display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "MODEL_LLAMA_3 = 'llama3'\n",
    "MODEL_qwen = 'qwen3:32b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c62db23-f91e-40d6-af88-e93c68a82d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_LLM(model,messages,llm_url=None):\n",
    "    if(llm_url):\n",
    "        open_ai = OpenAI(base_url=llm_url,api_key='ollama')\n",
    "    else:\n",
    "        open_ai = OpenAI()\n",
    "    stream = open_ai.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        stream = True\n",
    "    )\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b86d43a-dfd5-4958-9e67-b97cfc0f8c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(question, sys_prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b822e182-a824-4edf-9354-dfbfac02e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_models = [MODEL_GPT]\n",
    "local_models = [MODEL_LLAMA,MODEL_LLAMA_3,MODEL_qwen]\n",
    "# local_models = [MODEL_qwen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The code you provided uses a generator expression with the `yield from` statement, which allows it to yield values from an iterable (in this case, a set comprehension). Here's a breakdown of the components:\n",
       "\n",
       "1. **Set Comprehension**: \n",
       "   - `{book.get(\"author\") for book in books if book.get(\"author\")}` creates a set of unique authors from a collection of `books`.\n",
       "   - `book.get(\"author\")` retrieves the value associated with the \"author\" key in each `book` dictionary.\n",
       "   - The condition `if book.get(\"author\")` ensures that only books with a valid (non-None and non-empty) author are included in the set.\n",
       "\n",
       "2. **Yield from**:\n",
       "   - The `yield from` statement allows the function or generator where this code is used to yield each item from the set generated by the set comprehension. This means that each unique author will be returned one at a time but still allows the calling function to maintain state.\n",
       "\n",
       "3. **Overall Purpose**:\n",
       "   - The code effectively creates a generator that yields each unique author's name found in the `books` collection, excluding any books that do not have an author specified.\n",
       "\n",
       "### Example\n",
       "If `books` is a list of dictionaries like this:\n",
       "```python\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 2\", \"author\": \"Author B\"},\n",
       "    {\"title\": \"Book 3\"},\n",
       "    {\"title\": \"Book 4\", \"author\": \"Author A\"},\n",
       "]\n",
       "```\n",
       "The resulting output from the code would be the unique authors: `\"Author A\"` and `\"Author B\"`.\n",
       "\n",
       "### Why Use This Approach\n",
       "- **Uniqueness**: Using a set ensures that authors are unique (no duplicate entries).\n",
       "- **Lazy Evaluation**: Using `yield from` means authors are produced one at a time, which can be more memory efficient for large datasets compared to creating a list with all authors upfront."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "sys_prompt = \"You are a ai assistant to help the users to understand code. Restrain from answering any other non coding quetions\"\n",
    "for model in open_ai_models:\n",
    "    call_LLM(model=model,messages=get_prompt(question,sys_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- llama3.2 ---------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Code Explanation**\n",
       "\n",
       "This is a Python code snippet that uses the `yield from` syntax, which is part of the `async/await` features in Python.\n",
       "\n",
       "Here's what's happening:\n",
       "\n",
       "1. `{book.get(\"author\") for book in books if book.get(\"author\")}` is a generator expression.\n",
       "2. It iterates over the `books` sequence (e.g., a list or iterable).\n",
       "3. For each book, it checks if the \"author\" key exists using the `get()` method. If it doesn't exist (`None`), the book is skipped.\n",
       "4. If the \"author\" key exists, its value is yielded by the generator expression.\n",
       "\n",
       "The `yield from` syntax is used to delegate to another iterable (in this case, a generator expression) and yield its values.\n",
       "\n",
       "**Why do we need `yield from` here?**\n",
       "\n",
       "Without `yield from`, you would have had to create an intermediate list or other data structure to store the author names and then use that as input for... well, nothing. The `yield from` syntax allows us to lazily generate the values without having to keep them in memory.\n",
       "\n",
       "**Example Use Case**\n",
       "\n",
       "Here's a simple example:\n",
       "python\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"John Doe\"},\n",
       "    {\"title\": \"Book 2\"},\n",
       "    {\"title\": \"Book 3\", \"author\": \"Jane Smith\"}\n",
       "]\n",
       "\n",
       "def get_authors(books):\n",
       "    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "for author in get_authors(books):\n",
       "    print(author)  # prints John Doe, Jane Smith\n",
       "\n",
       "In this example, we define a generator function `get_authors()` that yields the author names. We use `yield from` to delegate to the generator expression, which lazily generates the values without storing them in memory.\n",
       "\n",
       "**Async/await Version**\n",
       "\n",
       "Here's how you might rewrite the same code using async/await syntax:\n",
       "python\n",
       "async def get_authors(books):\n",
       "    async for book in books:\n",
       "        if book.get(\"author\"):\n",
       "            yield await book[\"author\"]\n",
       "\n",
       "# similar usage as before\n",
       "for author in get_authors(books):\n",
       "    print(author)  # prints John Doe, Jane Smith\n",
       "\n",
       "In this version, we define an async function `get_authors()` that uses the `async for` loop and `yield await` syntax to delegate to a generator expression."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- llama3 ---------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This is Python code that uses a feature called generators (`yield`) to iterate over a set of authors. Here's a breakdown:\n",
       "\n",
       "1. `yield from ...`: This is used for generating a sequence of values, which can be useful when dealing with large datasets or when you need to implement cooperative multitasking (see [this guide](https://dev.to/tessel/go-indepth-yield-from-4a3j) for more info).\n",
       "\n",
       "2. `{book.get(\"author\") for book in books if book.get(\"author\")}`: This is a generator expression, which is like a compact version of a `for` loop that returns an iterator.\n",
       "\n",
       "The code above iterates over each \"book\" item in the `books` list and checks if it has an author (i.e., its `\"author\"` key exists) using `book.get(\"author\")`.\n",
       "\n",
       "If the book does have an author, it adds this author to a set (`{}`). This helps remove any duplicate authors from the output. Now you might wonder why we don't just use a conversion list like `[...]` instead of `{...}` since sets are unordered by default in Python. The reason is efficiency! \n",
       "\n",
       "So, after processing all books, this generator will \"yield\" each author (or more precisely, each unique author), effectively returning an iterator over the set of authors.\n",
       "\n",
       "The output essentially becomes a stream-based representation of book authors that have been found."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- qwen3:32b ---------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, let me try to figure out what this Python code does. The user provided an example using `yield from` combined with a set comprehension. So, the line is `yield from {book.get(\"author\") for book in books if book.get(\"author\")}`. \n",
       "\n",
       "First, I need to break down each part. The main components are `yield from` and the set comprehension. Let me start with the set comprehension. The curly braces mean it's a set, not a dictionary. The set comprehension is iterating over each `book` in `books`. For each book, it checks if `book.get(\"author\")` is truthy, and if so, includes the author in the set. The `get` method here retrieves the value associated with the key \"author\" from the dictionary `book`. If the author isn't present or is `None`, `get` would return `None`, which in a boolean context is considered falsy, so it's excluded.\n",
       "\n",
       "So the set comprehension is collecting all the authors from the books where the author exists. That means it filters out any books that don't have an \"author\" key or have a falsy value (like an empty string) there.\n",
       "\n",
       "Now, the `yield from` statement. I remember that `yield from` is used in generators to delegate to another iterable. So by using `yield from`, the generator function will yield each element from the iterable that follows. In this case, the iterable is the set of authors generated by the comprehension.\n",
       "\n",
       "Putting it all together: this line is generating a set of all authors from the books where the author is present, and then yielding each of those authors one by one in the generator. \n",
       "\n",
       "But wait, why a set? Using a set would eliminate duplicate authors. Since a set doesn't allow duplicate values, each author is unique in the result. So the generator will yield each unique author once.\n",
       "\n",
       "So the overall purpose of this code is to yield all unique authors from the list of books. The `yield from` is efficiently passing each element of the set to the caller. \n",
       "\n",
       "I need to make sure about the order. Since it's a set, the order isn't preserved. So if order matters, this code might not be suitable. Also, checking `if book.get(\"author\")` ensures that only non-null (non-falsy) authors are included. \n",
       "\n",
       "Let me see if there's a more explicit way to write this. An alternative could be to loop through each book, check for the author, add to a set, and then loop through the set. But the set comprehension and `yield from` is a concise way to achieve that.\n",
       "\n",
       "Another point: because it's a generator expression, it might be more memory efficient since the set is created in memory, but for a large dataset, that's okay. However, if `books` is extremely large, creating the set could use more memory compared to processing one by one, but the code's conciseness and clarity often make it acceptable.\n",
       "\n",
       "I should also mention that `book.get(\"author\")` could be equivalent to `book[\"author\"]` in cases where the key exists, but it's safer here because it doesn't raise a KeyError if the key isn't present. Instead, it returns `None`, which is filtered out by the `if` condition.\n",
       "\n",
       "Putting all these points together, the code filters each book for existing authors, collects unique ones into a set, and then yields each unique author in a generator using `yield from`.\n",
       "</think>\n",
       "\n",
       "The code `yield from {book.get(\"author\") for book in books if book.get(\"author\")}` is designed to **generate a sequence of unique author names from a collection of book dictionaries**. Here's a breakdown of its functionality:\n",
       "\n",
       "---\n",
       "\n",
       "### **1. Core Components**\n",
       "#### **a. Set Comprehension:**\n",
       "python\n",
       "{book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "- **Iterates** over each `book` in the `books` list.\n",
       "- For each `book`, it uses `book.get(\"author\")` to retrieve the value associated with the `\"author\"` key.\n",
       "- **Filters** out `None` values (via `if book.get(\"author\")`), ensuring only books with valid (truthy) author values are included.\n",
       "- **Creates a `set`** of authors. This ensures **uniqueness**: duplicates are automatically removed.\n",
       "\n",
       "#### **b. `yield from`**\n",
       "python\n",
       "yield from ...\n",
       "\n",
       "- Delegates to the iterable (in this case, the set of authors) and **yields each element directly** to the generator's caller.\n",
       "- This avoids the need to manually iterate and yield from the set.\n",
       "\n",
       "---\n",
       "\n",
       "### **2. Why This Code Works**\n",
       "- **Efficiency and Clarity**: The combination of `yield from` and a set comprehension is concise and expressive.\n",
       "- **Uniqueness**: The set ensures no duplicate author names are generated.\n",
       "- **Safety**: Using `.get(\"author\")` avoids `KeyError` exceptions for books without an `\"author\"` key.\n",
       "- **Filtering**: The `if book.get(\"author\")` condition excludes `None` values, ensuring only valid authors are included.\n",
       "\n",
       "---\n",
       "\n",
       "### **3. Equivalent Long-Form Code**\n",
       "To clarify the logic, here's the same functionality written in a more explicit way:\n",
       "python\n",
       "def get_authors(books):\n",
       "    seen = set()\n",
       "    for book in books:\n",
       "        author = book.get(\"author\")\n",
       "        if author:\n",
       "            seen.add(author)\n",
       "    for author in seen:\n",
       "        yield author\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "### **4. Use Case**\n",
       "This code is useful when:\n",
       "- You need to process a list of book records (likely dictionaries).\n",
       "- You want to extract **unique author names** while ignoring books with missing or invalid `\"author\"` fields.\n",
       "- The result should be a **lazy generator** (for memory efficiency, especially with large datasets).\n",
       "\n",
       "---\n",
       "\n",
       "### **Example**\n",
       "If `books = [\n",
       "    {\"title\": \"Book1\", \"author\": \"Alice\"},\n",
       "    {\"title\": \"Book2\", \"author\": \"Bob\"},\n",
       "    {\"title\": \"Book3\", \"author\": \"Alice\"},\n",
       "    {\"title\": \"Book4\"},\n",
       "]`\n",
       "\n",
       "The output would be: `Alice`, `Bob` (each yielded once, in arbitrary order).\n",
       "\n",
       "---\n",
       "\n",
       "### **Key Takeaways**\n",
       "- **`yield from`** delegates control to an iterable.\n",
       "- **Set comprehensions** ensure uniqueness.\n",
       "- **`.get()` with a filter** safely skips missing or falsy keys."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "for model in local_models:\n",
    "    print(\"-----------------------------------\",model,\"---------------------------------------\\n\")\n",
    "    call_LLM(model=model,messages=get_prompt(question,sys_prompt),llm_url=\"http://localhost:11434/v1\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1f0d7b6-ca4b-4b41-a59a-0a90d48cfb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- llama3 ---------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Let's break down this code, which is written in Python.\n",
       "\n",
       "`yield from` is a syntax feature specifically designed for generators. It means that the current generator will yield each value from the expression specified after `yield from`. \n",
       "\n",
       "In this case, `{book.get(\"author\") for book in books if book.get(\"author\")}` is a set comprehension, which creates a set of unique values from an iterable (`books`) by applying a condition.\n",
       "\n",
       "Here's what it does:\n",
       "\n",
       "1. Iterates over each `book` in the `books` collection.\n",
       "2. For each `book`, it checks if there's an \"author\" key and if its value is truthy (not `None`, not empty string, etc.). The `if book.get(\"author\")` part ensures only `books` with a non-empty author are processed.\n",
       "3. If the condition is met for a particular `book`, it adds the corresponding author to the set comprehension `{...}`.\n",
       "\n",
       "The resulting set contains unique authors from the `books`. Since sets automatically eliminate duplicates, you won't get any duplicate authors in your output.\n",
       "\n",
       "Overall, this code appears to be part of a larger generator function that yields each unique author from a collection of books."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- llama3.2 ---------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This line of code is written in Python and utilizes a feature called `yield` combined with the `for` loop, generator expressions, and dictionary lookup.\n",
       "\n",
       "Here's how it works:\n",
       "\n",
       "1. `yield from`: This keyword in Python is used to delegate sub-generators to a current generator instance.\n",
       "2. `{book.get(\"author\") for book in books if book.get(\"author\")}`: This is a generator expression that filters and extracts data from the `books` dictionary. \n",
       "\n",
       "   - The list comprehension (`...for ...if ...`) filters out dictionaries where \"author\" key does not exist (`book.get(\"author\")`). \n",
       "   - `book.get(\"author\")`: Returns the value of the \"author\" key for the `book` dictionary if it exists.\n",
       "\n",
       "Here's a simple breakdown:\n",
       "\n",
       "If there were actual lists in place of dictionaries, this line would be equivalent to: \n",
       "\n",
       "\n",
       "result = []\n",
       "for book in books:\n",
       "    if hasattr(book.get(\"author\")) != False:\n",
       "        result.append(book.get(\"author\"))\n",
       "yield from result\n",
       "\n",
       "\n",
       "However, the dictionary version makes for a much more concise code.\n",
       "\n",
       "It takes a dictionary where it finds book entries and uses a list comprehension to select only those that have \"author\" key present as its value. This would yield a generator object containing just the author names if \"author\" keys are present in all entries from books, or an empty iterator if they aren't within them.\n",
       "\n",
       "The `yield from` line essentially says \"yell for each of these sub-generators and delegate to them\". It sends these results back up to where the main program called this function."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in [\"llama3\",\"llama3.2\"]:\n",
    "    print(\"-----------------------------------\",model,\"---------------------------------------\\n\")\n",
    "    call_LLM(model=model,messages=get_prompt(question,sys_prompt),llm_url=\"http://localhost:11434/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a971119-7899-4ef7-a9c4-ec17737d860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- qwen3:32b ---------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, the user is asking about a Python code snippet they found. The code is:\n",
       "\n",
       "with result as stream:\n",
       "    for text in stream.text_stream:\n",
       "        print(text, end=\"\", flush=True)\n",
       "\n",
       "I need to break this down and explain what each part does. Let me start by looking at the syntax. The 'with' statement suggests that they're working with a context manager, which is common in Python for handling resources like files or network connections. The variable 'result' is being used in this context, but the code after 'as' assigns it to 'stream'. So, maybe 'result' is an object that acts as a context manager, and 'stream' is the resource being managed under that context.\n",
       "\n",
       "Next, there's a for loop iterating over 'stream.text_stream'. So 'text_stream' must be an iterable, maybe a generator or a stream of text chunks. Each 'text' in the loop is being printed using the print function. The parameters end=\"\" and flush=True are used. Normally, print adds a newline at the end, but here end is an empty string, so it prints without a newline. The flush=True ensures that the output is immediately written to the console, which is useful when appending to the output incrementally, like in a streaming scenario.\n",
       "\n",
       "Wait, this looks like code for handling a streaming response, maybe from an API. For example, when you get a streaming response in chunks, you might iterate through each chunk and print it as it arrives. Using the context manager with 'with' suggests that the stream needs to be properly managed, perhaps with setup and teardown, like opening a network connection.\n",
       "\n",
       "But the user didn't specify what 'result' is. Since 'result' is used in the 'with' statement, maybe it's from a library that provides a context manager for streams. For example, in the 'requests' library, when streaming a response with response.iter_content(), but that's a different approach. Another example could be from a library like 'openai' where you stream the response from a text generation API. The 'text_stream' might be an iterator over the chunks of text being received.\n",
       "\n",
       "So, the code's main purpose is to process each chunk of a streaming result and print it in real-time without newlines and ensuring each piece is flushed. This is useful for live updates or progressive data display.\n",
       "\n",
       "Wait, but 'with result as stream:' is a bit unclear. The standard 'with' syntax is 'with EXPRESSION [as VARIABLE]:'. So if 'result' is an object that returns the stream when entered, then 'stream' becomes that object. So 'result' might be a context manager that yields the stream when __enter__ is called. For example, a function that returns a context manager or a generator.\n",
       "\n",
       "Alternatively, maybe 'result' is a context manager itself, and when you 'with' it, it gives you 'stream' which has the .text_stream attribute. That makes sense. For instance, if result is initialized by some call that returns a context manager object. Let me think of possible libraries. For example, in some AWS SDKs, you might have a streaming context. But more likely, perhaps a custom or third-party library where the API returns a streamable object that's used in a 'with' block to handle resources properly.\n",
       "\n",
       "Another angle: the user might not be aware of the underlying object. They saw this code and want to understand how it works. My job is to explain the structure and purpose, but also note possible assumptions.\n",
       "\n",
       "In summary, the code opens a context using a manager (result), accesses the stream via 'stream', loops through each text chunk in its text_stream, and prints each chunk in real-time. The 'end' and 'flush' settings prevent newlines from being added and ensure immediate output.\n",
       "\n",
       "I should explain each part step by step, note the possible context where this code might be used (like streaming from an API or reading a file stream), and mention that 'result' is specific to their environment or library. Maybe give an example where 'result' could be a stream object from an API call, and 'text_stream' is an iterator of chunks.\n",
       "</think>\n",
       "\n",
       "The code is handling a **streaming result** that yields text in chunks (like a real-time API response or data source). Here's a breakdown:\n",
       "\n",
       "### **Step-by-Step Explanation**\n",
       "1. **Context Manager**  \n",
       "   python\n",
       "   with result as stream:\n",
       "     \n",
       "   - Uses a [context manager](https://docs.python.org/3/reference/compound_stmts.html#the-with-statement) to manage the resource (`result`).  \n",
       "   - `result` must be a context manager object (e.g., created via a function/method like `api_call()`).  \n",
       "   - `stream` becomes the active resource (e.g., a stream object with a `.text_stream` attribute).\n",
       "\n",
       "2. **Iterate Over Text Chunks**  \n",
       "   python\n",
       "   for text in stream.text_stream:\n",
       "     \n",
       "   - `stream.text_stream` is an iterable (likely a generator) that yields discrete `text` chunks as they arrive.  \n",
       "   - Example: Streaming from a text-generating API that delivers the output in parts.\n",
       "\n",
       "3. **Print in Real-Time**  \n",
       "   python\n",
       "   print(text, end=\"\", flush=True)\n",
       "     \n",
       "   - **`end=\"\"`**: Prevents `print()` from adding a newline after each chunk (avoids fragmented lines).  \n",
       "   - **`flush=True`**: Forces immediate display of text on the terminal instead of buffering (crucial for real-time output).\n",
       "\n",
       "---\n",
       "\n",
       "### **Example Use Case**\n",
       "This pattern is common in libraries that stream text output, such as:  \n",
       "- **LLM APIs** (e.g., OpenAI/Anthropic streaming responses)  \n",
       "- **Web scraping** (streaming partial HTML)  \n",
       "- **Command-line tools** (processing live data from subprocesses)\n",
       "\n",
       "---\n",
       "\n",
       "### **Typical Flow**\n",
       "python\n",
       "response = generate_stream()  # Returns a context manager\n",
       "with response as stream:\n",
       "    for chunk in stream.text_stream:\n",
       "        print(chunk, end=\"\", flush=True)  # Outputs: \"Hello wor...\" â†’ \"Hello world!\"\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "### **Assumptions**\n",
       "- `result` is a context manager returning a stream object with a `.text_stream` attribute.  \n",
       "- `text_stream` is an iterator that yields text chunks incrementally.  \n",
       "- The code is designed for **real-time output** (e.g., progress updates, live chat, or streaming audio/text).  \n",
       "\n",
       "This structure ensures resources are properly managed (via `with`) and output is displayed dynamically."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sys_prompt = \"You are a ai assistant to help the users to understand code. Restrain from answering any other non coding quetions\"\n",
    "\n",
    "\n",
    "question = \"\"\"\n",
    "with result as stream:\n",
    "    for text in stream.text_stream:\n",
    "            print(text, end=\"\", flush=True)\n",
    "\"\"\"\n",
    "for model in [MODEL_qwen]:\n",
    "    print(\"-----------------------------------\",model,\"---------------------------------------\\n\")\n",
    "    call_LLM(model=model,messages=get_prompt(question,sys_prompt),llm_url=\"http://localhost:11434/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789f3476-9a44-4d05-82a5-82b55be296af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
